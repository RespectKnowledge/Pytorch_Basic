{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_pipline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYvfbKId2CMG"
      },
      "source": [
        "# define model(input,output,forward pass)\r\n",
        "# define optimizer and loss\r\n",
        "# training loop\r\n",
        "  # forward pass: compute prediciton\r\n",
        "  # backward pass: calculate gradients\r\n",
        "  # update weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7_cRu3I234B",
        "outputId": "39afbb3c-f71c-447b-9fea-ed74455900f0"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "X=np.array([1,2,3,4],dtype=np.float32)\r\n",
        "Y=np.array([2,4,6,8],dtype=np.float32)\r\n",
        "w=0.0\r\n",
        "# model prediction\r\n",
        "def forward(x):\r\n",
        "  return w*x\r\n",
        "\r\n",
        "# define loss\r\n",
        "#MSE\r\n",
        "def loss(y,y_pred):\r\n",
        "  return ((y_pred-y)**2).mean()\r\n",
        "\r\n",
        "# define gradient\r\n",
        "def gradient(x,y,y_pred):\r\n",
        "  return np.dot(2*x,y_pred-y).mean()\r\n",
        "\r\n",
        "print(f\"prediciton before training f(5)={forward(5):.3f}\")\r\n",
        "\r\n",
        "# training\r\n",
        "learning_rate=0.01\r\n",
        "n_iter=10\r\n",
        "for epoch in range(n_iter):\r\n",
        "  # model prediction\r\n",
        "  y_pred=forward(X)\r\n",
        "\r\n",
        "  # compute loss\r\n",
        "  l=loss(y_pred,y)\r\n",
        "  # compute gradient\r\n",
        "  dw=gradient(x,y,y_pred)\r\n",
        "  # update the gradient\r\n",
        "  w-=learning_rate*dw\r\n",
        "  if epoch % 1==0:\r\n",
        "    print(f\"epoch:{epoch+1}: w:{w:.3f}, loss:{l:.8}\")\r\n",
        "print(f\"prediciton after training f(5)={forward(5):.3f}\")\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediciton before training f(5)=0.000\n",
            "epoch:1: w:1.200, loss:30.0\n",
            "epoch:2: w:1.680, loss:4.7999992\n",
            "epoch:3: w:1.872, loss:0.76800019\n",
            "epoch:4: w:1.949, loss:0.12288\n",
            "epoch:5: w:1.980, loss:0.019660834\n",
            "epoch:6: w:1.992, loss:0.0031457357\n",
            "epoch:7: w:1.997, loss:0.00050330802\n",
            "epoch:8: w:1.999, loss:8.0531863e-05\n",
            "epoch:9: w:1.999, loss:1.2884395e-05\n",
            "epoch:10: w:2.000, loss:2.0613531e-06\n",
            "prediciton before training f(5)=9.999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "409eclOm739M",
        "outputId": "bf27880e-8097-4759-fbf7-e1c4d0d175c7"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\r\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\r\n",
        "w=torch.tensor(0.0, dtype=torch.float32,requires_grad=True)\r\n",
        "# model prediction\r\n",
        "def forward(x):\r\n",
        "  return w*x\r\n",
        "\r\n",
        "# define loss\r\n",
        "#MSE\r\n",
        "def loss(y_pred,y):\r\n",
        "  return ((y_pred-y)**2).mean()\r\n",
        "\r\n",
        "# define gradient\r\n",
        "def gradient(x,y,y_pred):\r\n",
        "  return np.dot(2*x,y_pred-y).mean()\r\n",
        "\r\n",
        "print(f\"prediciton before training f(5)={forward(5):.3f}\")\r\n",
        "\r\n",
        "# training\r\n",
        "learning_rate=0.01\r\n",
        "n_iter=10\r\n",
        "for epoch in range(n_iter):\r\n",
        "  # model prediction\r\n",
        "  y_pred=forward(X)\r\n",
        "\r\n",
        "  # compute loss\r\n",
        "  l=loss(y_pred,Y)\r\n",
        "  l.backward()\r\n",
        "  # compute gradient\r\n",
        "  with torch.no_grad():\r\n",
        "    w-=learning_rate*w.grad\r\n",
        "  # zero gradient\r\n",
        "  w.grad.zero_()\r\n",
        "  if epoch % 1==0:\r\n",
        "    print(f\"epoch:{epoch+1}: w:{w:.3f}, loss:{l:.8}\")\r\n",
        "print(f\"prediciton after training f(5)={forward(5):.3f}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediciton before training f(5)=0.000\n",
            "epoch:1: w:0.300, loss:30.0\n",
            "epoch:2: w:0.555, loss:21.674999\n",
            "epoch:3: w:0.772, loss:15.660188\n",
            "epoch:4: w:0.956, loss:11.314487\n",
            "epoch:5: w:1.113, loss:8.1747169\n",
            "epoch:6: w:1.246, loss:5.9062324\n",
            "epoch:7: w:1.359, loss:4.2672529\n",
            "epoch:8: w:1.455, loss:3.0830898\n",
            "epoch:9: w:1.537, loss:2.2275321\n",
            "epoch:10: w:1.606, loss:1.6093917\n",
            "prediciton after training f(5)=8.031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwgdKqrt-MCj",
        "outputId": "497e569f-ffc9-47ee-f752-7c0047837002"
      },
      "source": [
        "# using pytorch espcially in optimizer and loss computation\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\r\n",
        "Y=torch.tensor([2,4,6,8],dtype=torch.float32)\r\n",
        "w=torch.tensor(0.0, dtype=torch.float32,requires_grad=True)\r\n",
        "# model prediction\r\n",
        "def forward(x):\r\n",
        "  return w*x\r\n",
        "\r\n",
        "# define loss\r\n",
        "#MSE\r\n",
        "#def loss(y_pred,y):\r\n",
        "#  return ((y_pred-y)**2).mean()\r\n",
        "\r\n",
        "# define gradient\r\n",
        "#def gradient(x,y,y_pred):\r\n",
        "#  return np.dot(2*x,y_pred-y).mean()\r\n",
        "\r\n",
        "loss=torch.nn.MSELoss()\r\n",
        "optimizer=torch.optim.SGD([w],lr=learning_rate)\r\n",
        "print(f\"prediciton before training f(5)={forward(5):.3f}\")\r\n",
        "\r\n",
        "# training\r\n",
        "learning_rate=0.01\r\n",
        "n_iter=10\r\n",
        "for epoch in range(n_iter):\r\n",
        "  # model prediction\r\n",
        "  y_pred=forward(X)\r\n",
        "\r\n",
        "  # compute loss \r\n",
        "  l=loss(y_pred,Y)\r\n",
        "  # backward pass and compute gradient\r\n",
        "  l.backward()\r\n",
        "  # update weights\r\n",
        "  optimizer.step()\r\n",
        "  # zero gradient\r\n",
        "  optimizer.zero_grad()\r\n",
        "  if epoch % 1==0:\r\n",
        "    print(f\"epoch:{epoch+1}: w:{w:.3f}, loss:{l:.8}\")\r\n",
        "print(f\"prediciton after training f(5)={forward(5):.3f}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediciton before training f(5)=0.000\n",
            "epoch:1: w:0.300, loss:30.0\n",
            "epoch:2: w:0.555, loss:21.674999\n",
            "epoch:3: w:0.772, loss:15.660188\n",
            "epoch:4: w:0.956, loss:11.314487\n",
            "epoch:5: w:1.113, loss:8.1747169\n",
            "epoch:6: w:1.246, loss:5.9062324\n",
            "epoch:7: w:1.359, loss:4.2672529\n",
            "epoch:8: w:1.455, loss:3.0830898\n",
            "epoch:9: w:1.537, loss:2.2275321\n",
            "epoch:10: w:1.606, loss:1.6093917\n",
            "prediciton after training f(5)=8.031\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAi40cp2AyrM",
        "outputId": "08aaf3a4-9621-48de-b965-b561d6cf0fe6"
      },
      "source": [
        "import torch\r\n",
        "import numpy as np\r\n",
        "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\r\n",
        "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\r\n",
        "n_samples,n_features=X.shape\r\n",
        "print(n_samples,n_features)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIeIxj3pAJKW",
        "outputId": "c1298885-7267-46a5-dcaf-881dd17be34e"
      },
      "source": [
        "# using pytorch basic linear model for regression\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "X=torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\r\n",
        "Y=torch.tensor([[2],[4],[6],[8]],dtype=torch.float32)\r\n",
        "X_test=torch.tensor([5], dtype=torch.float32)\r\n",
        "n_samples,n_features=X.shape\r\n",
        "print(n_samples,n_features)\r\n",
        "input_size=n_features\r\n",
        "output_size=n_features\r\n",
        "# define model\r\n",
        "model=nn.Linear(input_size,output_size)\r\n",
        "\r\n",
        "loss=torch.nn.MSELoss()\r\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\r\n",
        "print(f\"prediciton before training f(5)={model(X_test).item():.3f}\")\r\n",
        "\r\n",
        "# training\r\n",
        "learning_rate=0.01\r\n",
        "n_iter=100\r\n",
        "for epoch in range(n_iter):\r\n",
        "  # model prediction\r\n",
        "  y_pred=model(X)\r\n",
        "  # compute loss \r\n",
        "  l=loss(y_pred,Y)\r\n",
        "  # backward pass and compute gradient\r\n",
        "  l.backward()\r\n",
        "  # update weights\r\n",
        "  optimizer.step()\r\n",
        "  # zero gradient\r\n",
        "  optimizer.zero_grad()\r\n",
        "  if epoch % 10==0:\r\n",
        "    [w,b]=model.parameters()\r\n",
        "    print(f\"epoch:{epoch+1}: w:{w[0][0].item():.3f}, loss:{l:.8}\")\r\n",
        "print(f\"prediciton after training f(5)={model(X_test).item():.3f}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 1\n",
            "prediciton before training f(5)=3.466\n",
            "epoch:1: w:0.868, loss:12.564761\n",
            "epoch:11: w:1.684, loss:0.3616398\n",
            "epoch:21: w:1.819, loss:0.043787941\n",
            "epoch:31: w:1.844, loss:0.033560298\n",
            "epoch:41: w:1.852, loss:0.031408221\n",
            "epoch:51: w:1.857, loss:0.029574966\n",
            "epoch:61: w:1.861, loss:0.027853407\n",
            "epoch:71: w:1.866, loss:0.0262322\n",
            "epoch:81: w:1.870, loss:0.024705343\n",
            "epoch:91: w:1.873, loss:0.02326736\n",
            "prediciton after training f(5)=9.746\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}